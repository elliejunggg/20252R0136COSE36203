# -*- coding: utf-8 -*-
"""machinelearning_group5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wt-WSnv8ci_g-zAcd-Evny6NvhyfcL9s

# **전처리 과정**
"""

import nltk
import re
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import string
import math

## Download Resources
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download("vader_lexicon")

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.sentiment.util import *

from google.colab import drive
drive.mount('/content/drive')

# Progress bar
from tqdm import tqdm

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn import svm
from matplotlib.colors import ListedColormap
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, f1_score
from umap import UMAP
from collections import Counter

# Set global random seed
RANDOM_STATE = 2025
np.random.seed(RANDOM_STATE)

df = pd.read_csv('/content/drive/MyDrive/airlines_reviews.csv')
texts = df['Reviews'].astype(str)

# Preprocessing
punct = set(string.punctuation)
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    tokens = word_tokenize(text)
    tokens = [t for t in tokens if t not in punct]
    tokens = [t for t in tokens if t not in stop_words]
    tokens = [lemmatizer.lemmatize(t) for t in tokens]
    return " ".join(tokens)

df['processed_final'] = df['Reviews'].astype(str).apply(preprocess)

# Preprocessed dataset
df_preprocessed = df.copy()
df_preprocessed

"""# **Polarity 계산**"""

# Drop unnecessary columns and not verified data
df_final = df_preprocessed.drop(['Title', 'Name', 'Review Date', 'Type of Traveller', 'Month Flown', 'Route'], axis=1).query("Verified == 'True'")
df_final = df_final.assign(Recommended=lambda x: x['Recommended'].map({'yes': 1, 'no': 0}))
df_final = df_final.reset_index(drop=True)

# Since we only kept the verified data(rows), drop the column as we don't need it anymore
df_final = df_final.drop(['Verified'], axis=1)
df_final

# Use vader to evaluated sentiment of reviews
def evalSentences(sentences, to_df=False, columns=[]):
    # Instantiate an instance to access SentimentIntensityAnalyzer class
    # from vader in nltk
    sid = SentimentIntensityAnalyzer()
    pdlist = []
    if to_df:
        for sentence in tqdm(sentences):
            ss = sid.polarity_scores(sentence)
            pdlist.append([sentence]+[ss['compound']])
        reviewDf = pd.DataFrame(pdlist)
        reviewDf.columns = columns
        return reviewDf

    else:
        for sentence in tqdm(sentences):
            print("\n" + sentence)
            ss = sid.polarity_scores(sentence)
            for k in sorted(ss):
                print('{0}: {1}, '.format(k, ss[k]), end='')
            print()

reviews = df_final['Reviews'].values

# Dataframe with airlines, reviews and vader scores
df_vader = evalSentences(df_final['Reviews'].values, to_df=True, columns=['review','vader_score'])
df_vader = pd.concat([df_final['Airline'], df_vader], axis=1)
df_vader

"""# **Supervised Learning: Binary Classification**"""

# Add columns from vader dataframe to the final dataframe
df_final = pd.concat([df_final, df_vader[['vader_score']]], axis=1)
df_final

# Before applying any models, text data (preprocessed_review) should be converted as numerical features
# Apply text vectorization
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df_final['processed_final'])
y = df_final['Recommended']

# Divide the dataset using train_test_split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("-------Shape of train-test data---------")
print(f'Train feature shape: {X_train.shape}')
print(f'Test feature shape: {X_test.shape}')

# Divide the dataset using train_test_split (80% train, 20% test) for VADER
X_vader = df_final[['vader_score']]
y_vader = df_final['Recommended']

X_train_vader, X_test_vader, y_train_vader, y_test_vader = train_test_split(X_vader, y_vader, test_size=0.2, random_state=42)

print("-------Shape of train-test VADER data---------")
print(f'Train feature shape: {X_train_vader.shape}')
print(f'Test feature shape: {X_test_vader.shape}')

"""# **Model Comparison**

## 1. Logistic Regression
"""

# Build Logistic Regression model
logreg = LogisticRegression(random_state = 42)

# Train the model
logreg.fit(X_train, y_train)

# Predict on test set
y_pred = logreg.predict(X_test)

# Compute accuracy score
acc_logreg = accuracy_score(y_test, y_pred)

# Print evaluation results
print("=== Logistic Regression Evaluation Results ===")
print("Accuracy:", acc_logreg)
print(classification_report(y_test, y_pred))

# Plot confusion matrix as heatmap
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Logistic Regression Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""## 2. Logistic Regression using VADER"""

# Build Logistic Regression model using VADER
logreg_vader = LogisticRegression(random_state = 42)

# Train the model
logreg_vader.fit(X_train_vader, y_train_vader)

# Predict on test set
y_pred_vader = logreg_vader.predict(X_test_vader)

# Compute accuracy score
acc_logreg_vader = accuracy_score(y_test_vader, y_pred_vader)

# Print evaluation results
print("=== Logistic Regression using VADER Evaluation Results ===")
print("Accuracy:", acc_logreg_vader)
print(classification_report(y_test_vader, y_pred_vader))

# Plot confusion matrix as heatmap
cm = confusion_matrix(y_test_vader, y_pred_vader)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Logistic Regression using VADER Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""## 3. Random Forest"""

# Feature scaling: ensures all the features are on a similar scale
scaler = StandardScaler(with_mean=False)
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build the Random Forest Classifier
rfc = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rfc.fit(X_train_scaled, y_train)

# Predict on test set
y_pred_rfc = rfc.predict(X_test_scaled)

# Compute accuracy score
acc_rfc = accuracy_score(y_test, y_pred_rfc)

# Print evaluation results
print("=== Random Forest Classifier Evaluation Results ===")
print("Accuracy:", acc_rfc)
print(classification_report(y_test, y_pred_rfc))

# Plot confusion matrix as heatmap
cm = confusion_matrix(y_test, y_pred_rfc)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Random Forest Classifier Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""## 4. Bernoulli Naïve Bayes"""

# Build the Bernoulli Naive Bayes model
bnb = BernoulliNB()

# Train the model
bnb.fit(X_train, y_train)

# Predict on test set
y_pred_bnb = bnb.predict(X_test)

# Compute accuracy score
acc_bnb = accuracy_score(y_test, y_pred_bnb)

# Print evaluation results
print("=== Bernoulli Naive Bayes Evaluation Results ===")
print("Accuracy:", acc_bnb)
print(classification_report(y_test, y_pred_bnb))

# Plot confusion matrix as heatmap
cm = confusion_matrix(y_test, y_pred_bnb)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Bernoulli Naive Bayes Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""## 5. Linear Support Vector Machine (SVM)"""

# Build the Linear Support Vector Machine model
lsvm = svm.LinearSVC()

# Train the model
lsvm.fit(X_train, y_train)

# Predict on test set
y_pred_lsvm = lsvm.predict(X_test)

# Compute accuracy score
acc_lsvm = accuracy_score(y_test, y_pred_lsvm)

# Print evaluation results
print("=== Linear Support Vector Machine Evaluation Results ===")
print("Accuracy:", acc_lsvm)
print(classification_report(y_test, y_pred_lsvm))

# Plot confusion matrix as heatmap
cm = confusion_matrix(y_test, y_pred_lsvm)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Linear Support Vector Machine Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""## Compare the accuracy score"""

model = ['Logistic Regression', 'VADER Logistic Regression', 'Random Forest', 'Bernoulli Naive Bayes', 'Linear SVM']
accuracy = [acc_logreg, acc_logreg_vader, acc_rfc, acc_bnb, acc_lsvm]

plt.barh(model, accuracy)
plt.title('Accuracy Comparison')
plt.xlabel('Accuracy')
plt.ylabel('Model')
plt.show()

"""# **Class Comparison**"""

# Build Logistic Regression model
logreg_final = LogisticRegression(random_state = 42)

# Train the model
logreg_final.fit(X_train, y_train)

# Predict on the whole dataset
X_all = vectorizer.transform(df_final['Reviews'])
df_final['pos_rate'] = logreg_final.predict(X_all)

# Predict probability on test set
df_final['pos_prob'] = logreg_final.predict_proba(X_all)[:, 1]

# Create new dataframe
df_class = (
    df_final.groupby(['Airline', 'Class'])
    .agg(
        positive_rate = ('pos_rate', 'mean'),
        positive_probability = ('pos_prob', 'mean'),
        )
    .reset_index()
    .sort_values(['Airline','Class'])
)

df_class

# Combine positive_rate score and positive_probability score
df_class['positive_score'] = df_class['positive_rate'] * df_class['positive_probability']

# Print the dataframe for each class
for cls in df_class['Class'].unique():
    print(f'\n===== Top Airlines Ranking for {cls}=====\n')

    df_rank = df_class[df_class['Class'] == cls].sort_values('positive_score', ascending=False).reset_index(drop=True)
    df_rank['Rank'] = df_rank.index + 1
    df_rank = df_rank.set_index('Rank')
    display(df_rank[['Airline', 'positive_score']])

# Display top 5 Airlines for each class
for cls in df_class['Class'].unique():
  top5 = df_class[df_class['Class'] == cls].sort_values('positive_score', ascending=False).head(5)

  plt.figure(figsize=(5, 5))
  plt.bar(top5['Airline'], top5['positive_score'])
  plt.title(f'Top 5 Airlines for {cls}')
  plt.xlabel('Airline')
  plt.ylabel('Positive Score')
  plt.xticks(rotation=45)
  plt.tight_layout()
  plt.show()

"""#**Compare the Details**"""

# Only extract columns with numeric value
num_cols = df_final.select_dtypes(include=['int64']).columns.tolist()

# Drop Recommended and pos_rate column (unneeded)
remove_cols = ['Recommended', 'pos_rate']
num_cols = [col for col in num_cols if col not in remove_cols]

ranking_per_column = {}

for col in num_cols:
  df_avg = df_final.groupby('Airline')[col].mean().sort_values(ascending=False).reset_index()

  df_avg['Rank'] = df_avg.index + 1
  df_avg = df_avg.set_index('Rank')
  ranking_per_column[col] = df_avg

for col, table in ranking_per_column.items():
  print(f'\n===== Top Airlines Ranking for {col} =====\n')
  display(table)

# Display top 5 Airlines for each characteristics
for col, table in ranking_per_column.items():
  top5 = table.head(5)

  plt.figure(figsize=(5, 5))
  plt.bar(top5['Airline'], top5[col])
  plt.title(f'Top 5 Airlines for {col}')
  plt.xlabel('Airline')
  plt.ylabel(col)
  plt.xticks(rotation=45)
  plt.tight_layout()
  plt.show()